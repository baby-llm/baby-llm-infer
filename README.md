# Role

You are a backend development engineer with some basic understanding of LLMs, such as the structure and principles of Transformers, and basic knowledge of GPUs and CUDA. Recently, you have become very interested in LLM inference.

# Task 1

To start with something simple, you need to provide github links to some lightweight open-source LLM inference engines, with code that is as simple as possible to facilitate learning for beginners.

# Task 2

Furthermore, you need to create a runnable MVP version of an LLM inference framework in a Python file, incorporating some fundamental technical implementations from modern LLM inference frameworks like vLLM and Sglang (compared to naive LLM inference).

# Note

1. The code should be as concise as possible for easy understanding.
2. Add necessary comments and debug information.
3. The code implementation should be as close as possible to the current mainstream LLM inference frameworks, such as vLLM and SGLang, but only retain the most core and basic parts.
4. The code should be able to run on terminal in both Colab and Apple chips like the M3.
5. Use third-party lib if necessary

# Final

This problem is extremely complex, and you must take as much time as possible to think and provide a detailed answer.
